{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Acquisitions - Building Systems (learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "import re #Regular expressions\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple, Any #Supports typing hints for code documentation etc\n",
    "import pandas as pd\n",
    "from pathlib import Path #provides an object-oriented interface for working with filesystem paths.\n",
    "import logging\n",
    "\n",
    "import PyPDF2 #Used for reading, splitting, merging Pdf's etc\n",
    "import fitz # from pymupdf, peforms better than PyPDF2\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from watermark import watermark\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas    : 2.2.3\n",
      "fuzzywuzzy: 0.18.0\n",
      "PyPDF2    : 3.0.1\n",
      "pymupdf   : 1.24.11\n",
      "fitz      : 1.24.11\n",
      "logging   : 0.5.1.2\n",
      "re        : 2.2.1\n",
      "watermark : 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%watermark --iversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert PDF to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text on Page 2:\n",
      "~'. . 2 WILDLIFE CONSERVATION (AMENDMENT) ( REGULATIONS, 1989 ~~l~P~~'O!l' . 6B (1) No person shall keep a wild animal WJ d &OImas . .' ., • without' ,.as a pet unless he IS the .holder .of a licence licence! issued by the Chief Game and ·Wildlife Officer prohibited. or his representative for that purpose. . (2) Application for licence to keep a :\\.:' . wild animal asa pet shall be made in writing -,to the Chief Game and Wildlife Officer or ...... ,. hIS representative in the area of residence of the applicant accompanied by such fees as may be determined by the Chief Game and . Wildlife Officer. I\" :.' ,(3) The Chief Game. and Wildlife \" .( Officer may in granting a licence under this .' '.;'.' ,sej::tion stipulate the conditions under which the wild animal shall be kept . .i ;': '. . (4) A licence granted under this section r : may'forstatedreasons bewithdrawn and the pet confiscated to the State. ..'., (5) All fees collected forlicences issued .. '.;' ',. underthe regulation shall be paid into central !:; : . (r ,gQv~rDlll~n~ account. . (6) Any person who contravenes any of . the provisions or regulation 6A or 6B commits an offence and shall on conviction '~! be liable to a fine not exceeding Sl10,000.00 or to imprisonment for a term not exceeding 'i;;> 'twelve months or to both\". ' ...., .',' :' .(d) by t~e ~sert,ion immediately' after. sut9-regulation (1) (c) of :',' .. ~e~~~()h:9l,th<?reof o'the fdllowing,paraAphs; \" . \"'''(d)where he has reasonto suspect that the licence 'I .will be used for group hunting.or Wat clubs. , : \", ::, ',i isticks; cudgels or dogs will be used in'the hunt- '.\"\"\"!i'!';::\"~I1.;~.'. \" ..': .. '. \"':;\":'\" W).w\\lere theapplicant isknown to b~ involved '\", ,:'::'\" 1~ gt:'o~~hunt~ng :o~ ,~s~clated With group 'j. j, . ',: ;\\'{!) ,;h:untel's: ~ . . ,: ': (e~ by the insertion immediately after, .sub-regulation (2) of . ,regu~ti,Qn'i 14: thereof of \\l:te following: ; t ·;~.''!'(l)iWhere ail exporter has'been convicted of any :iilfiinpfi\\ent·.:against , any rules», regulations or dirt»- :\". tion~:relatitlg to' export' trade of wildlife such person .j. '~h:athbe:'bain.A.ed:fr()Itlexporting wildlife for such period as the Chief Game and Wildlife.Oftioer shall determine.\" : ! : - . ; 1\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Replace common OCR errors\n",
    "    replacements = {\n",
    "        '_.r': '',  # Remove this artifact\n",
    "        'fllO,OOO.OO': '₵10,000.00',  # Correct currency symbol\n",
    "        'Ju#\\'': 'July',  # Correct month\n",
    "        'L.I. 14S~.': 'L.I. 1452.',  # Correct regulation number\n",
    "        'W1LDUFE': 'WILDLIFE',  # Correct spelling\n",
    "        ';;r~din~': 'Trading',  # Correct word\n",
    "        'wi:ho~t': 'without',  # Correct word\n",
    "        '1icenc:e.': 'licence.',  # Correct word\n",
    "        'prohibnod.': 'prohibited.',  # Correct word\n",
    "        'A· licati I! li d': 'Application for licence under',  # Correct phrase\n",
    "        '0.•': 'or',  # Correct word\n",
    "        'whended': 'amended',  # Correct word\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    \n",
    "    # Correct spacing issues\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    extracted_data = defaultdict(str)\n",
    "    \n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            text = page.get_text(\"text\")\n",
    "            cleaned_text = clean_text(text)\n",
    "            extracted_data[page_num + 1] = cleaned_text\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "def display_text_on_page(extracted_data, page_number):\n",
    "    if page_number in extracted_data:\n",
    "        print(f\"Text on Page {page_number}:\\n{extracted_data[page_number]}\")\n",
    "    else:\n",
    "        num_pages = len(extracted_data)\n",
    "        if num_pages > 0:\n",
    "            print(f\"Page number {page_number} not found in the extracted data. Valid page numbers are 1 to {num_pages}\")\n",
    "        else:\n",
    "            print(\"No pages found in the extracted data. Make sure you have executed the code to extract data.\")\n",
    "\n",
    "def total_word_count(input_str):\n",
    "    words = input_str.split()  # Split the input string by spaces into a list of words\n",
    "    count = len(words)         # Count the number of words in the list\n",
    "    return count\n",
    "\n",
    "def word_occurrences(input_str):\n",
    "    word_count = {}\n",
    "    for word in input_str.split():\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "    return word_count\n",
    "\n",
    "text = \"this is a test this is only a test\"\n",
    "print(word_occurrences(text))  # Output: {'this': 2, 'is': 2, 'a': 2, 'test': 2, 'only': 1}\n",
    "\n",
    "\n",
    "\n",
    "# Usage\n",
    "pdf_path =  r\"C:\\Users\\ellio\\Desktop\\Personal\\Land Matters\\Lands Commission\\Head Office\\EI . LI's\\LEGISLATIVE INSTRUMENT, (1989)\\scan0001.pdf\"\n",
    "extracted_data = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Display text from a specific page\n",
    "page_number_to_display = 2\n",
    "display_text_on_page(extracted_data, page_number_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 15:20:09,701 - ERROR - Error processing PDF C:\\Users\\ellio\\Desktop\\Personal\\Land Matters\\Lands Commission\\Head Office\\EI . LI's\\LEGISLATIVE INSTRUMENT, (1989)\\scan0001.pdf: PDF file not found: C:\\Users\\ellio\\Desktop\\Personal\\Land Matters\\Lands Commission\\Head Office\\EI . LI's\\LEGISLATIVE INSTRUMENT, (1989)\\scan0001.pdf\n",
      "2024-10-25 15:20:09,705 - ERROR - Error exporting to CSV: Cannot save file into a non-existent directory: 'C:\\Users\\ellio\\Desktop\\Personal\\Land Matters\\Lands Commission\\Head Office\\EI . LI's\\LEGISLATIVE INSTRUMENT, (1989)'\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class PDFTextProcessor:\n",
    "    def __init__(self):\n",
    "        self.common_ocr_errors = {\n",
    "            '_.r': '',  # Remove this artifact\n",
    "            'fllO,OOO.OO': '₵10,000.00',  # Correct currency symbol\n",
    "            'Ju#\\'': 'July',  # Correct month\n",
    "            'L.I. 14S~.': 'L.I. 1452.',  # Correct regulation number\n",
    "            'W1LDUFE': 'WILDLIFE',  # Correct spelling\n",
    "            ';;r~din~': 'Trading',  # Correct word\n",
    "            'wi:ho~t': 'without',  # Correct word\n",
    "            '1icenc:e.': 'licence.',  # Correct word\n",
    "            'prohibnod.': 'prohibited.',  # Correct word\n",
    "            'A· licati I! li d': 'Application for licence under',  # Correct phrase\n",
    "            '0.•': 'or',  # Correct word\n",
    "            'whended': 'amended',  # Correct word\n",
    "        }\n",
    "        \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean and normalize text from PDF.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Apply OCR error corrections\n",
    "            for old, new in self.common_ocr_errors.items():\n",
    "                text = text.replace(old, new)\n",
    "            \n",
    "            # Advanced text cleaning\n",
    "            text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces\n",
    "            text = re.sub(r'([.!?])\\s*([A-Z])', r'\\1\\n\\n\\2', text)  # Add line breaks after sentences\n",
    "            text = re.sub(r'(\\d+\\.)\\s*([A-Z])', r'\\1\\n\\2', text)  # Add line breaks after numbered points\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in clean_text: {str(e)}\")\n",
    "            return text\n",
    "\n",
    "    def extract_pdf_text(self, pdf_path: str) -> Dict[int, str]:\n",
    "        \"\"\"\n",
    "        Extract and clean text from PDF file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pdf_path = Path(pdf_path)\n",
    "            if not pdf_path.exists():\n",
    "                raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "            \n",
    "            extracted_data = defaultdict(str)\n",
    "            with fitz.open(pdf_path) as doc:\n",
    "                for page_num in range(len(doc)):\n",
    "                    page = doc[page_num]\n",
    "                    text = page.get_text(\"text\")\n",
    "                    cleaned_text = self.clean_text(text)\n",
    "                    extracted_data[page_num + 1] = cleaned_text\n",
    "                    \n",
    "            return extracted_data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF {pdf_path}: {str(e)}\")\n",
    "            return defaultdict(str)\n",
    "\n",
    "    def analyze_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform comprehensive text analysis.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            words = text.split()\n",
    "            word_count = len(words)\n",
    "            \n",
    "            # Word frequency analysis\n",
    "            word_freq = Counter(words)\n",
    "            \n",
    "            # Basic statistics\n",
    "            analysis = {\n",
    "                'total_words': word_count,\n",
    "                'unique_words': len(word_freq),\n",
    "                'avg_word_length': sum(len(word) for word in words) / word_count if word_count > 0 else 0,\n",
    "                'most_common_words': word_freq.most_common(10),\n",
    "                'sentence_count': len(re.findall(r'[.!?]+', text)),\n",
    "            }\n",
    "            \n",
    "            return analysis\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in text analysis: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def export_to_csv(self, extracted_data: Dict[int, str], output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Export extracted text to CSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame.from_dict(extracted_data, orient='index', columns=['text'])\n",
    "            df.index.name = 'page_number'\n",
    "            df.to_csv(output_path)\n",
    "            logger.info(f\"Data exported to {output_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error exporting to CSV: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize processor\n",
    "    processor = PDFTextProcessor()\n",
    "    \n",
    "    # Process PDF\n",
    "    pdf_path =  r\"C:\\Users\\ellio\\Desktop\\Personal\\Land Matters\\Lands Commission\\Head Office\\EI . LI's\\LEGISLATIVE INSTRUMENT, (1989)\\scan0001.pdf\"\n",
    "    try:\n",
    "        # Extract text\n",
    "        extracted_data = processor.extract_pdf_text(pdf_path)\n",
    "        \n",
    "        # Analyze each page\n",
    "        for page_num, text in extracted_data.items():\n",
    "            print(f\"\\nPage {page_num} Analysis:\")\n",
    "            analysis = processor.analyze_text(text)\n",
    "            print(\"Word Count:\", analysis['total_words'])\n",
    "            print(\"Unique Words:\", analysis['unique_words'])\n",
    "            print(\"Average Word Length:\", f\"{analysis['avg_word_length']:.2f}\")\n",
    "            print(\"\\nMost Common Words:\")\n",
    "            for word, count in analysis['most_common_words']:\n",
    "                print(f\"  {word}: {count}\")\n",
    "        \n",
    "        # Export to CSV\n",
    "        output_path = Path(pdf_path).with_suffix('.csv')\n",
    "        processor.export_to_csv(extracted_data, output_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LandAcq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
